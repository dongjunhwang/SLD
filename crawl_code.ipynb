{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2aa9ecdf",
   "metadata": {},
   "source": [
    "## Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2b27d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlretrieve\n",
    "import os, time, sys\n",
    "from os.path import join as ospj\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "import imageio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c555011",
   "metadata": {},
   "source": [
    "## Crawling Images\n",
    "\n",
    "Please change API keys your own.  \n",
    "You can change `label_list` when you need to crawl specific classes.\n",
    "\n",
    "```\n",
    "label_list = ['chair', 'sofa', 'diningtable']\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8a719148",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flickrapi import FlickrAPI\n",
    "\n",
    "# API key information\n",
    "key = \"\"\n",
    "secret = \"\"\n",
    "wait_time = 1\n",
    "flickr = FlickrAPI(key, secret, format='parsed-json')\n",
    "\n",
    "# Set Parameter\n",
    "license_number = [1,2,4,5,9,10]\n",
    "extras = 'url_c, url_o, license, owner_name'\n",
    "search_photo_number = 4000\n",
    "label_list = ['chair']\n",
    "label_excluded_list = ['diningtable', 'person', 'sofa']\n",
    "\n",
    "# License Info\n",
    "license_info = flickr.photos.licenses.getInfo()['licenses']['license']\n",
    "license_info_print = {l_dict['id']: l_dict['url'] for l_dict in license_info}\n",
    "\n",
    "# save_path\n",
    "savedir = \"./Dataset/VOC/\"\n",
    "savedir_metadata = \"./Dataset/VOCmetadata/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6386742c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def photo_search(name, license_number, search_photo_number, excluded_list):\n",
    "    result_list = []\n",
    "    name = name + \" not \" + \" not \".join(excluded_list)\n",
    "    print(name)\n",
    "    for license_id in license_number:\n",
    "        result = flickr.photos.search(\n",
    "            text = name,\n",
    "            per_page = search_photo_number,\n",
    "            media = 'photos',\n",
    "            sort = 'relevance',\n",
    "            safe_search = license_id,\n",
    "            extras = extras,\n",
    "            license = license_id,\n",
    "        )\n",
    "        result_list.extend(result['photos']['photo'])\n",
    "    print(f\"We find {len(result_list)} photos\")\n",
    "    return result_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2f7be1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chair not diningtable not person not sofa\n",
      "We find 2998 photos\n"
     ]
    }
   ],
   "source": [
    "SEARCH_DICT = {}\n",
    "for label in label_list:\n",
    "    SEARCH_DICT[label] = {}\n",
    "    search_results = photo_search(label, license_number, search_photo_number, label_excluded_list)\n",
    "    for photo_dict in search_results:\n",
    "        filepath = savedir + '/' + photo_dict['id'] + '.jpg'\n",
    "        \n",
    "        url_q = photo_dict.get('url_c', None)\n",
    "        if url_q is None:\n",
    "            url_q = photo_dict.get('url_o', None)\n",
    "        urlretrieve(url_q, filepath)\n",
    "        \n",
    "        url = \"https://www.flickr.com/photos/\"+photo_dict['owner']+\"/\"+str(photo_dict['id'])\n",
    "        license_name = \"{},{},{},{}\".format(photo_dict['id'],\n",
    "                                            url,\n",
    "                                            license_info[int(photo_dict.get('license', None))],\n",
    "                                            photo_dict['ownername'])\n",
    "        SEARCH_DICT[label][photo_dict['id']] = license_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e703a3ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2997"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(SEARCH_DICT['chair'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d738a79f",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "118dd18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "entropy_threshold = 0.5\n",
    "prob_threshold = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1759f53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import importlib\n",
    "import numpy as np\n",
    "\n",
    "class TorchvisionNormalize():\n",
    "    def __init__(self, mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)):\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "\n",
    "    def __call__(self, img):\n",
    "        imgarr = np.asarray(img)\n",
    "        proc_img = np.empty_like(imgarr, np.float32)\n",
    "\n",
    "        proc_img[..., 0] = (imgarr[..., 0] / 255. - self.mean[0]) / self.std[0]\n",
    "        proc_img[..., 1] = (imgarr[..., 1] / 255. - self.mean[1]) / self.std[1]\n",
    "        proc_img[..., 2] = (imgarr[..., 2] / 255. - self.mean[2]) / self.std[2]\n",
    "\n",
    "        return proc_img\n",
    "    \n",
    "def gap2d(x, keepdims=False):\n",
    "    out = torch.mean(x.view(x.size(0), x.size(1), -1), -1)\n",
    "    if keepdims:\n",
    "        out = out.view(out.size(0), out.size(1), 1, 1)\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "99abee4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "CAT_LIST = ['aeroplane', 'bicycle', 'bird', 'boat',\n",
    "            'bottle', 'bus', 'car', 'cat', 'chair',\n",
    "            'cow', 'diningtable', 'dog', 'horse',\n",
    "            'motorbike', 'person', 'pottedplant',\n",
    "            'sheep', 'sofa', 'train',\n",
    "            'tvmonitor']\n",
    "\n",
    "model = getattr(importlib.import_module(\"net.resnet50_cam\"), 'CAM')()\n",
    "cam_weights = torch.load('sess/cam_retrain.pth')\n",
    "model.load_state_dict(cam_weights, strict=True)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e4eff608",
   "metadata": {},
   "outputs": [],
   "source": [
    "from misc import imutils\n",
    "\n",
    "def transform_img(img, img_normal, resize_long=(320, 640)):\n",
    "    img = imutils.random_resize_long(img, resize_long[0], resize_long[1])\n",
    "    img = img_normal(img).transpose((2,0,1))\n",
    "    img = np.stack([img, np.flip(img, -1)], axis=0)\n",
    "    img = torch.tensor(img).unsqueeze(0)\n",
    "    return img\n",
    "\n",
    "def th_delete(tensor, indices):\n",
    "    mask = torch.ones(tensor.numel(), dtype=torch.bool)\n",
    "    mask[indices] = False\n",
    "    return tensor[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572bbb38",
   "metadata": {},
   "outputs": [],
   "source": [
    "resize_long=(320, 640)\n",
    "img_normal = TorchvisionNormalize()\n",
    "log_softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "file_list = os.listdir(savedir)\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.cuda()\n",
    "    for label in label_list:\n",
    "        image_dict = SEARCH_DICT[label]\n",
    "        cat_index = CAT_LIST.index(label)\n",
    "        for image_id, license in image_dict.items():\n",
    "            # Import Image and Target\n",
    "            if image_id+\".jpg\" not in file_list:\n",
    "                continue\n",
    "                \n",
    "            img = imageio.imread(ospj(savedir, image_id+\".jpg\"), as_gray=False, pilmode=\"RGB\")\n",
    "            img_original = img.copy()\n",
    "            img = transform_img(img, img_normal)\n",
    "\n",
    "            output = model(img[0].cuda(non_blocking=True), return_norelu=True)\n",
    "            logits = gap2d(output[0].unsqueeze(0)).squeeze(0).cpu().detach()\n",
    "            \n",
    "            # Calculate Probability\n",
    "            logits = torch.sigmoid(logits)\n",
    "            logits_threshold = np.array(list(map(int, logits.numpy() > prob_threshold)))\n",
    "\n",
    "            # Calculate Entropy\n",
    "            label_value = logits[cat_index]\n",
    "            logits = th_delete(logits, [cat_index]).unsqueeze(0)\n",
    "            assert len(logits[0]) == len(CAT_LIST)-1\n",
    "            entropy = torch.neg(log_softmax(logits)).sum(dim=1)/len(CAT_LIST)\n",
    "            \n",
    "            nonzero_count = np.count_nonzero(logits_threshold)\n",
    "#             print(nonzero_count, logits_threshold[cat_index])\n",
    "            if nonzero_count == 1 and logits_threshold[cat_index] == 1:\n",
    "                print(image_id+\".jpg\")\n",
    "                plt.figure(figsize=(4,4))\n",
    "                plt.imshow(img_original)\n",
    "\n",
    "#             nonzero_count = np.count_nonzero(logits_threshold)\n",
    "#             if entropy > entropy_threshold or nonzero_count > 1:\n",
    "#                 image_dict.pop(image_id, None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd3e8980",
   "metadata": {},
   "source": [
    "### XML file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "31027427",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as elemTree\n",
    "\n",
    "def indent(elem, level=0):\n",
    "    i = \"\\n\" + level*\"  \"\n",
    "    if len(elem):\n",
    "        if not elem.text or not elem.text.strip():\n",
    "            elem.text = i + \"  \"\n",
    "        if not elem.tail or not elem.tail.strip():\n",
    "            elem.tail = i\n",
    "        for elem in elem:\n",
    "            indent(elem, level+1)\n",
    "        if not elem.tail or not elem.tail.strip():\n",
    "            elem.tail = i\n",
    "    else:\n",
    "        if level and (not elem.tail or not elem.tail.strip()):\n",
    "            elem.tail = i\n",
    "\n",
    "def make_xml(image_id, label, license, savedir, savedir_metadata):\n",
    "    filename = image_id + \".jpg\"\n",
    "    image_path = ospj(savedir, filename)\n",
    "    metadata_path = ospj(savedir_metadata, image_id + \".xml\")\n",
    "    \n",
    "    width, height = Image.open(image_path).size\n",
    "    \n",
    "    root = Element('annotation')\n",
    "    SubElement(root, 'folder').text = 'VOC2012'\n",
    "    SubElement(root, 'filename').text = filename\n",
    "    SubElement(root, 'path').text = image_path\n",
    "    \n",
    "    source = SubElement(root, 'source')\n",
    "    SubElement(source, 'license').text = license\n",
    "    SubElement(source, 'image').text = 'flickr'\n",
    "\n",
    "    size = SubElement(root, 'size')\n",
    "    SubElement(size, 'width').text = str(width)\n",
    "    SubElement(size, 'height').text = str(height)\n",
    "    SubElement(size, 'depth').text = '1'\n",
    "\n",
    "    SubElement(root, 'segmented').text = '0'\n",
    "\n",
    "    obj = SubElement(root, 'object')\n",
    "    SubElement(obj, 'name').text = label\n",
    "    SubElement(obj, 'pose').text = 'Unspecified'\n",
    "    SubElement(obj, 'truncated').text = '0'\n",
    "    SubElement(obj, 'difficult').text = '0'\n",
    "\n",
    "    indent(root)\n",
    "        \n",
    "    tree = ElementTree(root)\n",
    "    tree.write(metadata_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6576b43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for label in label_list:\n",
    "    image_dict = SEARCH_DICT[label]\n",
    "    for image_id, license in image_dict.items():\n",
    "        make_xml(image_id, label, license, savedir, savedir_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e870f01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d5a19a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18252c1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d75a02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b341770",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
